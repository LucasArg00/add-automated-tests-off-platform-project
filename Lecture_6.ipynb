{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasArg00/add-automated-tests-off-platform-project/blob/main/Lecture_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47a8OF0FzevE"
      },
      "source": [
        "# GFP Sequence to Function Model\n",
        "\n",
        "1.   Elemento de lista\n",
        "2.   Elemento de lista\n",
        "\n",
        "\n",
        "\n",
        "Code adapted from [David Brookes' CbAS](https://github.com/MauriceR71/CbAS-Restored)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ZdTvTyz9zT",
        "outputId": "a6d73e88-e489-4eb0-9737-3f4ff77f74ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!git clone https://github.com/igemto-drylab/lec6.git\n",
        "%cd lec6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'lec6' already exists and is not an empty directory.\n",
            "/content/lec6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B6mzWVHr7uk",
        "outputId": "b26450f8-73e9-4956-8f5b-7b3f10a984b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras import layers, initializers\n",
        "from keras.models import Model, load_model\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiHGRuOnuO7m"
      },
      "source": [
        "random.seed(1)\n",
        "\n",
        "AA = ['a', 'r', 'n', 'd', 'c', 'q', 'e', 'g', 'h', 'i', 'l', 'k', 'm', 'f', 'p', 's', 't', 'w', 'y', 'v', 'x']\n",
        "AA_upper = []\n",
        "for m_aa in AA:\n",
        "    AA_upper.append(m_aa.upper())\n",
        "\n",
        "AA_IDX = {AA_upper[i]:i for i in range(len(AA_upper))}\n",
        "\n",
        "def one_hot_encode_aa(aa_str):\n",
        "    M = len(aa_str)\n",
        "    aa_arr = np.zeros((M, 21), dtype=int)\n",
        "    for i in range(M):\n",
        "        aa_arr[i, AA_IDX[aa_str[i].upper()]] = 1\n",
        "    return aa_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnwquhcwu6vn"
      },
      "source": [
        "def get_data(train_size, ignore_stops=True):\n",
        "    data_df = pd.read_csv(\"gfp_data.csv\")\n",
        "\n",
        "    idx = data_df.index\n",
        "    data_df = data_df.loc[idx]\n",
        "\n",
        "    if ignore_stops:\n",
        "        idx = data_df.loc[~data_df['aaSequence'].str.contains('!')].index\n",
        "    data_df = data_df.loc[idx]\n",
        "\n",
        "    seqs = data_df['aaSequence']\n",
        "\n",
        "    M = len(seqs[0])\n",
        "    N = len(seqs)\n",
        "    X = np.zeros((N, M, 21))\n",
        "    j = 0\n",
        "    for i in idx:\n",
        "        X[j] = one_hot_encode_aa(seqs[i])\n",
        "        j += 1\n",
        "    y = np.array(data_df['medianBrightness'][idx])\n",
        "\n",
        "    # zip and shuffle data\n",
        "    data_list = list(zip(X, y))\n",
        "    random.shuffle(data_list)\n",
        "    X, y = zip(*data_list)\n",
        "\n",
        "    return np.array(X)[:train_size], np.array(y)[:train_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQoa7CQBrtFA"
      },
      "source": [
        "def build_model(M):\n",
        "    x = Input(shape=(M, 21,))\n",
        "    y = Flatten()(x)\n",
        "    y = Dense(50, activation='elu')(y)\n",
        "    y = Dense(2)(y)\n",
        "    model = Model(inputs=x, outputs=y)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Pvws1u4G1d"
      },
      "source": [
        "def neg_log_likelihood(y_true, y_pred):\n",
        "    y_true = y_true[:, 0]\n",
        "    mean = y_pred[:, 0]\n",
        "    variance = K.softplus(y_pred[:, 1]) + 1e-6\n",
        "    log_variance = K.log(variance)\n",
        "    return 0.5 * K.mean(log_variance, axis = -1) + 0.5 * K.mean(K.square(y_true - mean) / variance, axis = -1) + 0.5 * K.log(2 * np.pi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB0wYTKNriFm"
      },
      "source": [
        "def train_oracles_helper(X_train, y_train, num_models, batch_size=25):\n",
        "    for i in range(num_models):\n",
        "        model = build_model(X_train.shape[1])\n",
        "        model.compile(optimizer='adam',\n",
        "                      loss=neg_log_likelihood,\n",
        "                      )\n",
        "        early_stop = EarlyStopping(monitor='val_loss',\n",
        "                                   min_delta=0,\n",
        "                                   patience=5,\n",
        "                                   verbose=1)\n",
        "        # print(model.summary())\n",
        "        model.fit(X_train, y_train,\n",
        "                  epochs=250,\n",
        "                  batch_size=batch_size,\n",
        "                  validation_split=0.1,\n",
        "                  callbacks=[early_stop],\n",
        "                  verbose=2)\n",
        "        model.save(\"/content/lec6/oracle_model_%i.h5\" % i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZx0fyIrsqkE"
      },
      "source": [
        "def train_oracles():\n",
        "    i = 1\n",
        "    num_models = 5\n",
        "    for i in range(num_models):\n",
        "        X_train, y_train = get_data(train_size=10000)  # data has 58417 seqs\n",
        "\n",
        "        suffix = '_%i' % num_models\n",
        "        train_oracles_helper(X_train, y_train, num_models, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pHn55ul1R_E"
      },
      "source": [
        "def make_prediction():\n",
        "    for i in range(num_models):\n",
        "        vec = np.array([one_hot_encode_aa(s)])\n",
        "        model = load_model(\"/content/lec6/oracle_model_%i.h5\" % i)\n",
        "        predictions.append(model.predict(vec))\n",
        "    print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur_9Xqyt3hCE"
      },
      "source": [
        "train_oracles()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR5Chjy_1wiu"
      },
      "source": [
        "# seq must have the same number of amino acids as those in the training set\n",
        "# missing amino acids may be denoted by 'x'\n",
        "seq = \"\"\n",
        "\n",
        "make_predictions(seq)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}